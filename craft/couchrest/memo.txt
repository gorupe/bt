**bigdata(1ノード16G)試験
・1レコード200Kbで75,000,000レコード=15Gの想定
インサート結果→大量データをインサートしたら全体的に不安定な感じに・・・
結局37000000レコード=7.3Gまで追加できたが、indexingにかなりの時間がかかるようになり動きが遅い。

・indexingが終了すればかなり高速にviewが動作するようになった。


***インポート方法
ツールで行う。

cbdocloader.exe -n 192.168.255.255 -u user -p pass -b gamesim "C:\Program Files\Couchbase\Server\samples\"gamesim-sample.zip

-q クォータオプションもあり。
zipの中身はjson。

下記のようなディレクトリ構成にすることで、view定義もインポートすることが可能。

/design_docs/{design_docs名}.json
/docs/{id}.json


jsonファイル名はスペースを取り除くこと。(idとして使用されるため。)
エラーの可能性は下記の3種類
1）適切な形式のファイルでない場合。
2）資格情報が正しくない場合。
3）JSONを格納する新しいバケット用のRAMクォータが現在のクォータより大きい場合。

***エクスポート方法
・バックアップ方法
"C:\Program Files\Couchbase\Server\bin\cbtransfer.exe" -u user -p pass http://192.168.255.255:8091/ c:\trans
or
"C:\Program Files\Couchbase\Server\bin\cbbackup.exe" -u user -p pass http://192.168.255.255:8091/ c:\trans

「bucket-バケット名」という形式でDLされる。
中身はバケット情報design.jsonとsqlite形式のDB。

・リストア方法
C:\Program Files\Couchbase\Server\bin>"C:\Program Files\Couchbase\Server\bin\cbrestore.exe" -u user -p pass c:\trans http://192.168.255.255:8091 -b beer-sample
※あらかじめバケットが作成されてないとリストアできない


***その他
リバランスを行うとアクセスできない。
ノード追加などはメンテ期間を設けて行うこと。

20000件から全走査して1件抽出viewのレスポンスが平均0.1秒以下。

**検討事項
・セキュリティの設定(IPで制御？)
・近藤さんいわく、API-coreにjavaのcouchbaseライブラリを入れて直接連携してもいいんじゃない？とのこと。

**ノード連携に失敗する場合
couchbase間はIPを識別子として連携する。
IPの設定は下記のファイルにIPアドレスを設定し再起動すれば変更される。
var/lib/couchbase/ip_start

***windowsの場合
"C:\Program Files\Couchbase\Server\bin\service_stop.bat"
"C:\Program Files\Couchbase\Server\bin\service_unregister.bat"
"C:\Program Files\Couchbase\Server\bin\service_register.bat" ns_1@192.168.5.2
"C:\Program Files\Couchbase\Server\bin\service_start.bat"

**RESTでのcouchbase操作＆couchbaseにおけるCRUD
***Create
8091へPOSTしてバケットを作成できる。
{code}
curl -i -u user -X POST http://192.168.255.255:8091/pools/default/buckets -d authType=none -d replicaNumber=1 -d name=testuser -d ramQuotaMB=128 -d proxyPort=11220
{/code}

***Read
API:8092番を使用してviewを参照できる。
{code}
http://192.168.255.255:8092/beer-sample/_design/beer/_view/brewery_beers/
{/code}

***Update
同じIDで上書き

***Delete
OperationFuture<Boolean> delete = client.delete("key");




*インフラ設計

**2.0.1から2.1へアップグレード
couchbase2.1がエンタープライズエディションだけでリリースされた。
コミュニティエディションを使っていたが、rpmをダウンロードしてきてそのままアップグレードで更新できた。
wget http://packages.couchbase.com/releases/2.1.0/couchbase-server-enterprise_x86_64_2.1.0.rpm
sudo rpm -Uvh couchbase-server-enterprise_x86_64_2.1.0.rpm

※本番運用が始まったらやらないほうが無難。


**物理メモリをカーネルが占有？
どのプロセスもメモリを使っていないのに半分以上メモリがusedの状態に。
[[参考>http://www.atmarkit.co.jp/ait/articles/0903/25/news131.html]]
のような状態が発生していた模様。
大容量の読み書きをしていくと徐々に使えるメモリが少なくなっていくため
定期的にリブートする必要があるかもしれない。
(※管理画面の「Server Nodes」を見れば外部からでも確認可能。)



**LBの設計方針
本番機を２台同じ構成(HTTPサーバーも同じ)にし、LBでトランザクションを振り分ける。
マルチポイント方式。


**クォータの変更方法
コマンドラインツール「couchbase-cli」を使用してクォータのメモリサイズを変更できる。
/opt/couchbase/bin/couchbase-cli cluster-init -c localhost -u user -p pass --cluster-init-ramsize=1024

**設定の注意点
下記ポートをcouchbaseで使用するためFWで利用可能にする必要あり。
8091:webコンソール
8092:API

4369:Erlang Port Mapper (epmd)
11209:Internal Cluster Port(ノード間のみ)
11210:Internal Cluster Port(ノードからクライアントOK)
11211:Client interface (proxy)

(21100 to 21199 (inclusive))


**開発環境
開発段階ではEnterpriseEditionを利用しバグ発生を抑える。
2013/04/23時点でのバージョンは2.0.1。POSIXもwindowsも64bit版と32bit版の両方が存在する。
[[ダウンロード:http://www.couchbase.com/download]]


***Couchbaseインストール手順
wget http://packages.couchbase.com/releases/2.0.1/couchbase-server-enterprise_x86_64_2.0.1.rpm
sudo rpm -ivh couchbase-server-enterprise_x86_64_2.0.1.rpm

***構築メモ
言語：ruby 1.9.3系(ruby 1.9.3p392 (2013-02-22) [i386-mingw32])
Webサーバー：thin
フレームワーク：sinatra
XMLパーサー：nokogiri

***gem
couchbase (1.2.3 x86-mingw32, 1.2.2 x86-mingw32)
json (1.7.7, 1.5.5)
nokogiri (1.5.9 x86-mingw32)
sinatra (1.4.2, 1.3.5)
thin (1.5.1)

***サーバー情報
IP 192.168.255.255 192.168.255.255
OS CentOS5.8

http://192.168.255.255:8091/
user / pass でログインできます。
flushは有効。レプリケーションは無しです。


**テスト環境
[[minimalCentOS:http://thecloudmarket.com/image/ami-586bd859--centos6-2-x86-64]]
AWS(EC2)
CentOS

[[クラウドワークス:http://cloudworks.jp/]]
スケジュールジョブにより日中のみの稼動にすれば半額くらいに抑えられる。

**本番環境
AWS(EC2)
CentOS

※クラウド管理サービスのrightscaleを利用してインスタンスの増設や切り替えを行うのが主流らしい・・・
[[rightscale:http://www.rightscale.com/]]

MAX秒間120PV
検索エンジンは最速0.07秒


*AWS価格表いわく
データ転送(イン)に関しては無償でできるものとして、データ転送(アウト)に関して試算。
フロント画面は秒間400リクエストがあると仮定して、送信するレコメンド情報(XML)を10Kb程度とする。

10*400=1秒間に4Mb送信
60*60*24*4=345,600Mb ≒ 350Gb

「10 TB まで/月	$0.201 Gb あたり」とあるので、
350*0.201 = 70.35

ということでおよそひと月70ドルくらい。

**EC2試算
***ラージタイプ(オンデマンド)で試算。

Large(m1.large) 2コア メモリ7.5Gi 850G $0.35/時 *2台
$512.4/m

データ転送(out) 約$70を合わせると 月々 $589.79
→年間$7077

1年間リザーブインスタンスを使用した場合 $0.136/時となり
$245.3/mとなり、ほぼ半額となる。


***倍のスペック エクストララージタイプで資産。
ExtraLarge(m1.xlarge) 4コア メモリ14Gi 1690G $0.70/時 *2台
$1024.8/m
(単純に倍額に)

データ転送(out) 約$70を合わせると 月々 $1212.4


[[参考:http://aws.amazon.com/jp/ec2/?utm_source=JP_AdWords&utm_medium=cpc&utm_campaign=CPC_JPGoogle_01_AWS_Ex_00006_P2&00N500000026nJd=CPC_JPGoogle_01_AWS_Ex_00006_P2#legal]]


*Couchbaseマニュアルいわく

**RAM
全てのワーキングセットが収まるように十分なメモリを割り当てることが非常に重要です。
新しいデータ用の十分な空きメモリがない場合、一部のドキュメントがメモリから排出され、
ディスク上にのみ存在するようになります。
ディスクへのアクセスはメモリ内のデータに比べはるかに遅くなります。
その結果、もしメモリから排出されたデータが頻繁にアクセスされる場合、
クラスタのパフォーマンスが低下します。

**ノード数
クラスタに必要なメモリサイズが分かったら、次に少数の大きなノードか、
より多くの小さなノードにするかを決定する必要があります。

小さなノードを増やせばその分 I/O アクセスを分散できますが、
ノードが故障する可能性も（クラスタ全体において）高くなります。

少数の大きなノードでは、ノード故障が発生した場合、
アプリケーションへの影響は大きくなります。

これは、信頼性と効率のトレードオフです。

**コア数
CouchbaseはCPU性能より、メモリやI/O性能に影響されます。
しかし、Couchbaseは少なくとも2つのコアを持つマシンで利用するのが効率的です。

**ストレージの種類
データ格納先として、SSD（ソリッドステートドライブ）か回転式ディスクドライブが選択できます。
SSDは回転式メディアよりも高速ですが、現在は高コストです。
SSDの場合、I/Oのバッファキューサイズが小さいため、Couchbaseで必要となるメモリも少なくなります。

**WANデプロイメント
CouchbaseはWAN構成で使用するためのものではありません。
Couchbaseはサーバノード間およびサーバノードとCouchbaseクライアント間のレイテンシが非常に低いことを必要とします。

[[参考:http://www.couchbase.com/docs/couchbase-manual-1.8-ja/couchbase-bestpractice-clusterdesign.html]]


*いわく
http://www.thumbtack.net/solutions/ThumbtackWhitePaper.html
http://www.slideshare.net/bengber/no-sql-presentation
http://www.thumbtack.net/solutions/documents/Ultra-HighPerformanceNoSQLBenchmarking.pdf



**JAVA or other?
Couchbaseインスタンスをシングルトン(＆マルチスレッド)で実装する場合、JAVAだと問題があるかもしれません。
[[参考:http://www.ibm.com/developerworks/jp/java/library/j-dcl/]]


**レコメンドロジック
||ルールベース|コンテンツベース&br;(メタに依存)|協調フィルタリング&br;(実績に依存)|ネットワーク分析&br;(ベイジアンなど)|h
|~アーティスト軸||||?|
|~楽曲軸||||?|
|~ジャンル軸||||?|
|~ユーザー軸||-||?|

フロント画面の見せ方として、3つ枠があるとして下記のようにロジックを分けて表示する想定。
1.ランキングに近いもの
2.同一ジャンル
3.年代

また、今後の方針として、
アクセスログ→Myアー→購入実績
と、より正確性の高い情報を取り入れる。

インプットする情報は下記。
これらを元に5つ程度のアイテム情報を返却する。

RAWデータをbucketに入れ、ロジック毎にviewを用意する方針で。



**haml2xml
{code}
%recommend
    %artist_id
      = aid
{/code}


**RubyClientLibraryのインストール手順
[[参考:http://www.couchbase.com/develop/ruby/current]]

libcouchbaseというCライブラリを入れてからgemでインストールする
[[参考:http://www.couchbase.com/develop/c/current]]

***RHEL/CentOS 5.5
{code}
sudo wget -O/etc/yum.repos.d/couchbase.repo http://packages.couchbase.com/rpm/couchbase-centos55-x86_64.repo

sudo yum check-update
sudo yum install -y  libcouchbase2 libcouchbase-devel

sudo gem install couchbase
{/code}
※いまのところうまくいかないのでlibcouchbaseをgithubから落としてコンパイル。
足りないものがあった場合は都度インストール。

確認
{code}
ruby -rrubygems -rcouchbase -e 'puts Couchbase::VERSION'
=>1.3.0 (2013/05/16 10:42時点)
{/code}

*XML件
jsonでデータが格納されているので

json->xml
{code}
<recommends>
  <楽曲ID1>
    <key>value</key>
    <key>value</key>
  </楽曲ID1>
  <楽曲ID2>
    <key>value</key>
    <key>value</key>
  </楽曲ID2>
</recommends>
{/code}

こんな感じのxmlで。


*テスト戦略
GETreq取得→データ取得→res返却
POSTreq取得→データ処理→データ取得→res返却

＜モデル(DB接続)＞
・接続できること
・接続できなかったらエラー
・データの取得
・データの挿入
・遅かったら遅延アラート

＜ビュー(REST通信)＞
・GET→引数なし
・POST→IDを取得
・PUT→登録はしないため未使用(DWH側からの利用はアリかも？)
・DELETE→未使用の想定

・インポート
・エクスポート
・エラー処理
・バリデーション


*懸念点
・バリデーションはどうする？
→スキーマを定義してチェックする？

・エラーハンドリングの方針？
→APIからrequestを受け取って0.5秒経過したら遮断する方向で。
(フロント側がajaxで対応する必要あり？)

・デプロイの方法は？
git pushしたら反映されるようなのがいい

・couchbaseが異常終了した場合のリカバリなど




